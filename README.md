# Talks by Jesper Dramsch

## All Talks

<!-- TALKS -->
### Increase citations, ease review & collaboration â€“ Making machine learning in research reproducible

| Event | Location | Date | Link | Video | Slides |
| ----- | -------- | ---- | ---- | ----- | ------ |
| Euroscipy 2022 | Basel, Switzerland | 2022-09-01 | [Euroscipy](https://pretalx.com/euroscipy-2022/talk/8RAJX7/) | | [Slides](2022-09-01%20Euroscipy/) |

> Every scientific conference has seen a massive uptick in applications that use some type of machine learning. Whether itâ€™s a linear regression using scikit-learn, a transformer from Hugging Face, or a custom convolutional neural network in Jax, the breadth of applications is as vast as the quality of contributions.
>
> This tutorial aims to provide easy ways to increase the quality of scientific contributions that use machine learning methods. The reproducible aspect will make it easy for fellow researchers to use and iterate on a publication, increasing citations of published work. The use of appropriate validation techniques and increase in code quality accelerates the review process during publication and avoids possible rejection due to deficiencies in the methodology. Making models, code and possibly data available increases the visibility of work and enables easier collaboration on future work.
>
> This work to make machine learning applications reproducible has an outsized impact compared to the limited additional work that is required using existing Python libraries.
### How to Guarantee No One Understands What You Did in Your Machine Learning Project

| Event | Location | Date | Link | Video | Slides |
| ----- | -------- | ---- | ---- | ----- | ------ |
| SSI Fellowship 2022 | Online | 2021-10-30 | [SSI](https://dramsch.net/ssi) | [Video](https://youtu.be/wxMZxbui4Bg) | [Slides](2021-10-31%20SSI%20Fellowship%20Application/) |

##### ðŸ” THE REPRODUCIBILITY CRISIS
Machine learning can do amazing feats. BUT time and time again, we see problems reproducing the findings.

Why?

- Randomness of neural networks
- Software versions
- Different hardware
- Proprietary data
- Proprietary labels

##### ðŸ’¥ SUSTAINABLE MACHINE LEARNING APPLICATIONS
Let's educate researchers not in ML on how to make their awesome experiments using ML reproducible.

The plan from the video: ðŸ› ï¸ Create a workshop for ML applications ðŸŽ¥ Keep going with YouTube âœ’ï¸ Write more articles ðŸ“£ More Talks

##### ðŸ› ï¸ THE WORKSHOP
What does Workshop for Sustainable Machine Learning applications in Research look like?

Open to ideas, here's a start

- fix random seeds
- provide software versions
- use best practices
- interpretable and explainable AI

Maybe PyData will have me?

##### ðŸŽ¥ KEEP YOUTUBE GOING
My Youtube revolves around

- ðŸ¤– machine learning
- ðŸ’¾ data science
- ðŸ Python programming
- ðŸ‘” careers

And I love talking about making these accessible. Access to open software is at the core of making research reproducible and good.


##### âœ’ï¸WRITING
I wrote 60 articles last year.

These two fall squarely into the content that will help you make machine learning work in your research.

> Get a Software Person!

> If Your Model Doesn't Work, Make it Smaller

##### ðŸ“£ TALKS

I have presented a bunch of my research, but that's very different to giving a PyData conference talk.

With the help of the amazing mentors for first-timers like myself, I started the "How to Guarantee ..." - series

There's a playlist.

#### CONCLUSION

For this Software Sustainability Institute 2022 fellowship I plan to:

- Create a workshop for ML applications
- Keep going with YouTube
- Write more articles
- Give More Talks

### How to Guarantee No One Understands What You Did in Your Machine Learning Project

| Event | Location | Date | Link | Video | Slides |
| ----- | -------- | ---- | ---- | ----- | ------ |
| Pydata Global 2021 | Online | 2021-10-30 | [Pydata](https://pydata.org/global2021/schedule/presentation/112/how-to-guarantee-no-one-understands-what-you-did-in-your-machine-learning-project/) | [Video](https://www.youtube.com/watch?v=ucgCGGb088E) | [Slides](2021-10-28%20Pydata%20Global/) |

> Data science and machine learning can be a lot of fun. Freshly out of university, a bootcamp, or through the grinder of a Kaggle competition, we learned all the neat technical tricks. Suddenly that's only a basic requirement to get a job or even make anyone interested in your machine learning project. Let's dissect that.
>
> Working on a model for a few days, researching the architecture, perfecting all the tweaks and fixing all the leakage can make us forget that we're the only one that deep into the material. I sure do. But technobabble will not get us anywhere. The problem is that no one else is that deep into it or necessarily even cares. Depending on the company you keep, it may even be worse. I'm originally a geophysicist. Among physicists, you have a large number of people highly sceptical of machine learning. Talking too much about the specifics of the machine learning model may be actively detrimental. Funnily, sometimes we have the completely opposite problem, like I do at my new job. I'm amongst people who run circles around me on the topic of classic statistics. Yet, and this may come as a surprise, they know less than me about machine learning.
>
> So how do we fix that? How do we scale that gap? (And how do we make this into an interesting Talk?)
>
> Communicating machine learning and data science means building trust with your stakeholders. (Be they your job interviewer, grant coordinator, colleagues, or management at a job.)
>
> There's a specific time and place for talking shop, and that's when you're with other mechanics. In this talk, I will dive into the more abstract understanding of setting expectations around machine learning with stakeholders in the beginning. Then we'll progress into tools and strategies to communicate machine learning results to people who don't necessarily care about machine learning.
>
> We'll explore specific tools from machine learning explainability, interpretability and touch on causality. We'll talk about ethical considerations. We'll explore helpful visualizations and tools for interactivity. Finally, we talk about model validation specific to different expert domains and tie it all together.
<!-- //TALKS -->


## Tech

Marp based: https://marp.app/#get-started


## License

[![CC BY 4.0][cc-by-image]][cc-by]

Text, slides, arrangement and ideas communicated are licensed under a
[Creative Commons Attribution 4.0 International License][cc-by].

Images are often from Unsplash and do not fall under this license.
